# -*- coding: utf-8 -*-
"""Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17dxDeLtB_ValgLlh53Ec6YbtbqY2m9Y3

#Predictive Analytics - Prediksi Harga Saham PT Telekomunikasi Indonesia Tbk (TLKM.JK)

## Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import keras
from keras.models import Sequential
from keras.callbacks import EarlyStopping
from keras.layers import Dense, LSTM, Dropout

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

"""## Data Loading
Dataset yang digunakan bersumber dari kaggle: https://www.kaggle.com/datasets/irfansaputranst/dataset-saham-tlkm-jk

Dataset ini terdiri dari 7 kolom diantaranya:
- **Date**    : Tanggal pencatatan data dalam format DD/MM/YYYY.
- **Adj Close**: Harga penutupan yang telah disesuaikan untuk memberikan nilai lebih akurat, termasuk dividen dan pembagian saham.
- **Close**    : Harga penutupan pada akhir hari perdagangan.
- **High **    : Harga tertinggi yang dicapai saham pada hari perdagangan tersebut.
- **Low**      : Harga terendah yang dicapai saham pada hari perdagangan tersebut.
- **Open**     : Harga pembukaan saham di awal hari perdagangan.
- **Volume**   : Jumlah volume saham yang diperdagangkan pada hari tersebut (dalam format angka bertitik, perlu diubah ke format numerik untuk analisis).
"""

df = pd.read_csv('/content/SAHAM - PT Telekomunikasi Indonesia Tbk (TLKM.JK) - Sheet1.csv')
df.head()

"""#Exploratory Data Analysis

##Deskripsi Variabel
"""

df.info()

"""Note: Type data pada kolom date dan volume masih belum sesuai, maka perlu dilakukan mengubah type data,

date = objet > datetime dan

volume = object > float
"""

#Ubah kolom 'Date' ke format datetime (DD/MM/YYYY)
df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')
df.set_index('Date', inplace=True)

# Ubah kolom 'Volume' ke float
# Hilangkan titik pemisah ribuan terlebih dahulu
df['Volume'] = df['Volume'].str.replace('.', '', regex=False).astype(float)

# Cek hasil
print(df.dtypes)
print(df.head())

#Statistik deskriiptif setelah mengubah tipe data
df.describe()

"""##Menangani Missing Value dan Outliers"""

df.isnull().sum()

df.duplicated()

sns.boxplot(x=df['Adj Close'])

sns.boxplot(x=df['Close'])

sns.boxplot(x=df['High'])

sns.boxplot(x=df['Low'])

sns.boxplot(x=df['Volume'])

"""Note: Terdapat outlier pada kolom volume.

metode IQR digunakan untuk mengatasi outlier
"""

#Menghitung Q1, Q3, dan IQR hanya untuk kolom Volume
Q1 = df['Volume'].quantile(0.25)
Q3 = df['Volume'].quantile(0.75)
IQR = Q3 - Q1

filter_outliers = ~((df['Volume'] < (Q1 - 1.5 * IQR)) |
                    (df['Volume'] > (Q3 + 1.5 * IQR)))

df = df[filter_outliers]
# Cek ukuran dataset setelah outlier dihapus
df.shape

sns.boxplot(x=df['Volume'])

#Memeriksa jumlah nilai unique pada tiap kolom
print("\n=== UNIQUE VALUES PER COLUMN ===")
for col in df.columns:
    print(f"{col}: {df[col].nunique()} unique values")
    if df[col].dtype == 'object':
        print(f"  Values: {df[col].unique()}")
    print()

"""## Analisis Korelasi Antar Variabel"""

sns.pairplot(df, diag_kind = 'kde')

# Heatmap Korelasi
plt.figure(figsize=(10, 6))
correlation_matrix = df.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Note:

- Korelasi antara Adj Close, Close, Open, High, Low sangat tinggi (0.90 – 1.00). Hal ini menunjukan bahwa harga-harga saham ini berjalan sangat selaras, karena: Harga buka, tutup, tertinggi, dan terendah harian biasanya berbeda tipis. Close dan Adj Close hampir identik, perbedaannya terletak pada penyesuaian dividen/split
- Korelasi volme dengan semua kolom sangat rendah dan negatif (-0.08 s/d -0.13) Hal ini menunjukan bahwa Volume tidak punya hubungan linier kuat dengan harga.

## Visualisasi Data
"""

#visualisasi untuk melihat distribusi perbandingan harga pada kolom close dan open

plt.figure(figsize=(8, 6))
sns.histplot(df['Close'], color='skyblue', label='Close Price', kde=True)
sns.histplot(df['Open'], color='lightcoral', label='Open Price', kde=True)
plt.title('Distribusi Perbandingan Harga Close dan Open')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.legend()
plt.show()

"""Note:

- Harga penutupan cenderung lebih tinggi dari harga pembukaan.
- Kedua distribusi sangat mirip dan saling tumpang tindih, yang mengindikasikan bahwa secara umum, tidak ada perbedaan signifikan antara harga pembukaan dan penutupan dalam jangka panjang.
"""

#Melihat trend harga terendah dan harga tertinggi
plt.figure(figsize=(12, 6))
plt.plot(df.index, df['High'], label='Harga Tertinggi', color='blue', alpha=0.7, linewidth=1.5)
plt.plot(df.index, df['Low'], label='Harga Terendah', color='green', alpha=0.7, linewidth=1.5)

plt.title('Pergerakan Harga Tertinggi & Terendah Saham TLKM (2019–2024)', fontsize=14, fontweight='bold')
plt.xlabel('Tanggal', fontsize=12)
plt.ylabel('Harga (IDR)', fontsize=12)
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

"""**Insight**
- Perbedaan antara garis biru (harga tertinggi) dan garis hijau (harga terendah) mencerminkan volatilitas harian, yaitu tingkat fluktuasi harga dalam satu hari. Semakin besar jaraknya, semakin tinggi tingkat volatilitas harian saham.
- Harga saham menunjukkan tren kenaikan yang konsisten dari pertengahan 2021 hingga mencapai puncaknya pada pertengahan 2022.
- Harga tertinggi dan harga terendah cenderung bergerak seiring, yang menunjukkan tidak terdapat anomali ekstrem atau pergerakan harga yang tidak wajar selama periode tersebut.
"""

# Pastikan index datetime
df.index = pd.to_datetime(df.index)

# Ambil data tahun 2024 saja
df_2024 = df[df.index.year == 2024]

# Ambil 30 hari terakhir
df_last_30 = df_2024.tail(30)

plt.figure(figsize=(8,4))
sns.histplot(df_last_30['Volume'], kde=True, bins=15, color='blue')
plt.title('Distribusi Jumlah Volume Saham - 30 Hari Terakhir 2024')
plt.xlabel('Volume Saham (unit)')
plt.grid(alpha=0.3)
plt.show()

"""##Modelling

###Normalisasi dan Splitting Data
"""

# Pisahkan fitur dan target
X = df.drop(columns=['Adj Close'])
y = df['Adj Close'].values.reshape(-1, 1)  # Ubah ke array 2D agar bisa di-scale

#Standardisasi data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled = scaler.fit_transform(X)

# Split data menjadi train dan test dengan 80% untuk data train dan 20% data test
train_size = int(len(scaled) * 0.8)
test_size = len(scaled) - train_size
train, test = scaled[0:train_size,:], scaled[train_size:len(scaled),:]

print(f"Train Size: {len(train)}")
print(f"Test Size: {len(test)}")

"""###Modelling dengan LSTM"""

# Fungsi untuk membuat dataset berbasis window time series
def create_dataset(data, time_step=60):
    X, y = [], []
    for i in range(time_step, len(data)):
        X.append(data[i-time_step:i, 0])  # 60 time steps sebagai feature
        y.append(data[i, 0])              # Nilai berikutnya sebagai target
    return np.array(X), np.array(y)

# Membuat training set
time_step = 60
X_train, y_train = create_dataset(train, time_step)

# Membuat test set
X_test, y_test = create_dataset(test, time_step)

# Reshape input untuk LSTM [samples, time steps, features]
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_test shape: {y_test.shape}")

#Membuat model dengan LSTM
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    Dropout(0.3),
    LSTM(64, return_sequences=False),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dense(16, activation='relu'),
    Dense(1)
])

model.compile(optimizer='adam',
              loss='mean_squared_error',
              metrics=['mean_absolute_error'])

model.summary()

early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=100,
    batch_size=32,
    callbacks=[early_stop],
    verbose=1
)

"""Note:

Dengan menggunakan EarlyStopping, pelatihan akan otomatis dihentikan jika nilai validation loss tidak membaik. Setelah pelatihan berhenti, model akan otomatis mengembalikan bobot terbaik (dengan val_loss terendah), bukan yang terakhir.
"""

#Visualisasi hasil training dan validasi
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.plot(history.history['mean_absolute_error'], label='Training MAE')
plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')
plt.title('Model Loss dan MAE Selama Pelatihan')
plt.ylabel('Nilai')
plt.xlabel('Epoch')
plt.legend()
plt.show()

"""Note:

Dari grafik dapat disimpulkan bahwa tidak ada indikasi kuat terjadinya overfitting. hal tersebut terlihat dari gap antara training loss dan validation loss yang tidak terlalu besar.

### Prediksi & Evaluasi
"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import numpy as np

# Prediksi & inverse transform
predictions = model.predict(X_test)
predictions = scaler_y.inverse_transform(predictions)
y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))


# Evaluasi
mse = mean_squared_error(y_test_actual, predictions)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test_actual, predictions)
mape = np.mean(np.abs((y_test_actual - predictions) / y_test_actual)) * 100
r2 = r2_score(y_test_actual, predictions)

print(f"\nTest MSE: {mse:.4f}")
print(f"Test RMSE: {rmse:.4f}")
print(f"Test MAE: {mae:.4f}")
print(f"Test MAPE: {mape:.2f}%")
print(f"R² Score: {r2:.4f}")

"""Note: Score R² mencapai 96% dan MAPE sangat rendah menunjukan bahwa model LSTM sudah baik"""

# Visualisasi hasil prediksi
plt.figure(figsize=(12,6))
plt.plot(y_test_actual, label='Actual', color='blue', linewidth=2)
plt.plot(predictions, label='Predicted', color='orange', linewidth=2, linestyle='--')
plt.title('LSTM Predictions vs Actual')
plt.xlabel('Time Step')
plt.ylabel('Close Price (Actual Scale)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""### Kesimpulan
Hasil Evaluasi Model:

Model yang dibangun menunjukkan performa prediksi yang sangat baik, dengan akurasi tinggi dan nilai prediksi yang sangat dekat dengan nilai aktual. Hal ini ditunjukkan oleh hasil evaluasi berikut:

- Mean Squared Error (MSE): 5832.5618
- Root Mean Squared Error (RMSE): 76.3712
- Mean Absolute Error (MAE): 55.8816
- Mean Absolute Percentage Error (MAPE): 2.10%
- R² Score: 0.9685

Nilai R² sebesar 0.9685 mengindikasikan bahwa model mampu menjelaskan sekitar 96.85% variasi pada data target. Sementara itu, nilai MAPE yang rendah (2.10%) menunjukkan kesalahan prediksi relatif yang sangat kecil terhadap nilai aktual.

Dengan kombinasi error yang rendah dan R² yang tinggi, serta perbandingan performa training dan testing yang konsisten (diasumsikan tidak overfit), dapat disimpulkan bahwa model tidak mengalami overfitting dan memiliki generalisasi yang baik terhadap data baru.



"""

